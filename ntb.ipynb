{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 11:08:30.948423: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-20 11:08:31.103696: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-20 11:08:31.644991: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mt/miniconda3/envs/tf/lib/:/home/mt/miniconda3/lib/:/home/mt/miniconda3/envs/tf/lib/\n",
      "2022-11-20 11:08:31.645083: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/mt/miniconda3/envs/tf/lib/:/home/mt/miniconda3/lib/:/home/mt/miniconda3/envs/tf/lib/\n",
      "2022-11-20 11:08:31.645092: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-20 11:08:32.218982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 11:08:32.225025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 11:08:32.225216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "import scipy.signal as sps\n",
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(path,new_rate = 16000):\n",
    "    sampling_rate, data = wavfile.read(path)\n",
    "    samples = round(len(data) * float(new_rate) / sampling_rate)\n",
    "    new_data = sps.resample(data, samples)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def js_to_np(path,max_len=50):    \n",
    "    f = open(path)\n",
    "    data = json.load(f)\n",
    "    t=[[j['e'] for j in i['l']] for i in data]\n",
    "    t=[j for i in t for j in i]\n",
    "    if (len(t)>50): t=t[:50]\n",
    "    return np.pad(t,(0,50-len(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inp():\n",
    "    ds=[\"data/train/songs/\"+f for f in os.listdir(\"data/train/songs/\") if os.path.isfile(os.path.join(\"data/train/songs/\", f))]\n",
    "    for i in ds:\n",
    "        label=i.replace(\"songs\",\"labels\").replace(\"wav\",\"json\")\n",
    "        t=np.mean(resample(i),axis=1)\n",
    "        yield (librosa.feature.melspectrogram(y=np.pad(t,(0,480000-len(t))),sr=16000),js_to_np(label))\n",
    "x=[]\n",
    "y=[]\n",
    "for i in inp():\n",
    "    x.append(i[0])\n",
    "    y.append(i[1])\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "with open('test.npy', 'wb') as f:\n",
    "    np.save(f, x)\n",
    "    np.save(f, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.npy', 'rb') as f:\n",
    "    x = np.load(f)\n",
    "    y = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 11:13:48.613947: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-20 11:13:48.618565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 11:13:48.618909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 11:13:48.619071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 11:13:49.727634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 11:13:49.728069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 11:13:49.728245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-20 11:13:49.729052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4457 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2022-11-20 11:13:49.911999: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 507630592 exceeds 10% of free system memory.\n",
      "2022-11-20 11:13:50.310448: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 507630592 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 11:13:55.085976: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 15s 90ms/step - loss: 53514652.0000 - mae: 5151.3364\n",
      "Epoch 2/50\n",
      "106/106 [==============================] - 9s 88ms/step - loss: 43939008.0000 - mae: 4619.7915\n",
      "Epoch 3/50\n",
      "106/106 [==============================] - 9s 88ms/step - loss: 43664892.0000 - mae: 4582.7642\n",
      "Epoch 4/50\n",
      "106/106 [==============================] - 9s 89ms/step - loss: 41398244.0000 - mae: 4355.2168\n",
      "Epoch 5/50\n",
      "106/106 [==============================] - 9s 89ms/step - loss: 40332992.0000 - mae: 4194.2832\n",
      "Epoch 6/50\n",
      "106/106 [==============================] - 9s 89ms/step - loss: 39182584.0000 - mae: 4084.6235\n",
      "Epoch 7/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 37492696.0000 - mae: 3915.0310\n",
      "Epoch 8/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 35862952.0000 - mae: 3720.9771\n",
      "Epoch 9/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 34608996.0000 - mae: 3572.4543\n",
      "Epoch 10/50\n",
      "106/106 [==============================] - 10s 92ms/step - loss: 32284398.0000 - mae: 3324.7373\n",
      "Epoch 11/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 29664078.0000 - mae: 3024.9497\n",
      "Epoch 12/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 29082268.0000 - mae: 2940.4993\n",
      "Epoch 13/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 28637990.0000 - mae: 2884.7896\n",
      "Epoch 14/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 27977924.0000 - mae: 2812.6494\n",
      "Epoch 15/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 27822930.0000 - mae: 2796.9592\n",
      "Epoch 16/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 26962364.0000 - mae: 2697.4905\n",
      "Epoch 17/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 26332624.0000 - mae: 2611.4771\n",
      "Epoch 18/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 26231112.0000 - mae: 2607.0635\n",
      "Epoch 19/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 25738302.0000 - mae: 2553.2356\n",
      "Epoch 20/50\n",
      "106/106 [==============================] - 10s 92ms/step - loss: 24845200.0000 - mae: 2471.4031\n",
      "Epoch 21/50\n",
      "106/106 [==============================] - 10s 92ms/step - loss: 24045508.0000 - mae: 2396.8364\n",
      "Epoch 22/50\n",
      "106/106 [==============================] - 10s 92ms/step - loss: 23565346.0000 - mae: 2351.2856\n",
      "Epoch 23/50\n",
      "106/106 [==============================] - 10s 92ms/step - loss: 23682916.0000 - mae: 2345.0493\n",
      "Epoch 24/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 23302724.0000 - mae: 2305.1653\n",
      "Epoch 25/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 23109976.0000 - mae: 2290.2048\n",
      "Epoch 26/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 22990718.0000 - mae: 2270.4302\n",
      "Epoch 27/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 22774594.0000 - mae: 2232.8901\n",
      "Epoch 28/50\n",
      "106/106 [==============================] - 10s 94ms/step - loss: 22747320.0000 - mae: 2231.6621\n",
      "Epoch 29/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 22692622.0000 - mae: 2229.9485\n",
      "Epoch 30/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 22142848.0000 - mae: 2141.6104\n",
      "Epoch 31/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 22713678.0000 - mae: 2236.3848\n",
      "Epoch 32/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 22562980.0000 - mae: 2212.4226\n",
      "Epoch 33/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 22431194.0000 - mae: 2206.7446\n",
      "Epoch 34/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 22500156.0000 - mae: 2207.7917\n",
      "Epoch 35/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 22293982.0000 - mae: 2174.8018\n",
      "Epoch 36/50\n",
      "106/106 [==============================] - 10s 92ms/step - loss: 21963922.0000 - mae: 2133.0405\n",
      "Epoch 37/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 21696448.0000 - mae: 2115.3157\n",
      "Epoch 38/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 21784076.0000 - mae: 2116.8713\n",
      "Epoch 39/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 21679814.0000 - mae: 2121.8301\n",
      "Epoch 40/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 21629766.0000 - mae: 2096.2500\n",
      "Epoch 41/50\n",
      "106/106 [==============================] - 10s 94ms/step - loss: 21502362.0000 - mae: 2094.3330\n",
      "Epoch 42/50\n",
      "106/106 [==============================] - 10s 94ms/step - loss: 21707556.0000 - mae: 2100.8145\n",
      "Epoch 43/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 21643288.0000 - mae: 2086.2622\n",
      "Epoch 44/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 21486132.0000 - mae: 2068.1196\n",
      "Epoch 45/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 21284370.0000 - mae: 2060.4680\n",
      "Epoch 46/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 21147528.0000 - mae: 2014.5031\n",
      "Epoch 47/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 21157732.0000 - mae: 2009.4740\n",
      "Epoch 48/50\n",
      "106/106 [==============================] - 10s 93ms/step - loss: 20663218.0000 - mae: 1976.3285\n",
      "Epoch 49/50\n",
      "106/106 [==============================] - 10s 92ms/step - loss: 20604098.0000 - mae: 1975.6899\n",
      "Epoch 50/50\n",
      "106/106 [==============================] - 10s 92ms/step - loss: 20692700.0000 - mae: 1954.9437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd62a8f49d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(1028)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1028,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(512,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(256,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(128,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(50,activation = 'relu')\n",
    "])\n",
    "model.compile(loss=\"mse\",optimizer='adam',metrics=[\"mae\"])\n",
    "model.fit(x=x,y=y, batch_size=10, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_to_js(pred,path):\n",
    "    f = open(path)\n",
    "    data = json.load(f)\n",
    "    count=0\n",
    "    pre=0\n",
    "    pre_c=0\n",
    "    for i in data:\n",
    "        for j in i['l']:\n",
    "            j['s']=pre\n",
    "            j['e']=int(round(pred[0][count])) if count < 50 else 0\n",
    "            pre=int(round(pred[0][count])) if count < 50 else 0\n",
    "            count=count+1\n",
    "        i['e']=pre\n",
    "        i['s']=pre_c\n",
    "        pre_c=pre        \n",
    "    with open(path, \"w\",encoding='utf8') as outfile:\n",
    "        json.dump(data, outfile, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out():\n",
    "    ds=[\"data/public_test/songs/\"+f for f in os.listdir(\"data/public_test/songs/\") if os.path.isfile(os.path.join(\"data/public_test/songs/\", f))]\n",
    "    for i in ds:\n",
    "        label=i.replace(\"songs\",\"lyrics/new_labels_json\").replace(\"wav\",\"json\")\n",
    "        t=np.mean(resample(i),axis=1)\n",
    "        t=librosa.feature.melspectrogram(y=np.pad(t,(0,480000-len(t))),sr=16000)\n",
    "        pred = model.predict(tf.expand_dims(t,0))\n",
    "        np_to_js(pred,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "out()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26dae6e2463eaa5657e3fcec8b75b4b449e613ce58da87f135849ab74b192c50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
